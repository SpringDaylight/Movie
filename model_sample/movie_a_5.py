"""
A-5: LLM ê¸°ë°˜ í™•ë¥  ê·¼ê±° ë¬¸êµ¬ ìƒì„±

A-3ì—ì„œ ê³„ì‚°ëœ ë§Œì¡± í™•ë¥  ê²°ê³¼ë¥¼ ë°›ì•„ì„œ
ìì—°ì–´ë¡œ "ì™œ ì´ ì˜í™”ê°€ ë‹¹ì‹ ì—ê²Œ ë§ëŠ”ì§€" ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
from typing import Dict, List, Optional
import os
from dotenv import load_dotenv
import boto3

load_dotenv()


def get_bedrock_client():
    """AWS Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    try:
        bedrock_runtime = boto3.client(
            service_name='bedrock-runtime',
            region_name=os.getenv('AWS_REGION', 'us-east-1'),
            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')
        )
        return bedrock_runtime
    except Exception as e:
        print(f"âš ï¸  Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def generate_explanation(
    prediction_result: Dict,
    movie_title: str,
    user_liked_tags: List[str] = None,
    user_disliked_tags: List[str] = None,
    bedrock_client=None
) -> str:
    """
    ë§Œì¡± í™•ë¥  ê²°ê³¼ë¥¼ ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ë³€í™˜
    
    Args:
        prediction_result: calculate_satisfaction_probabilityì˜ ê²°ê³¼
        movie_title: ì˜í™” ì œëª©
        user_liked_tags: ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” íƒœê·¸ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        user_disliked_tags: ì‚¬ìš©ìê°€ ì‹«ì–´í•˜ëŠ” íƒœê·¸ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        bedrock_client: Bedrock í´ë¼ì´ì–¸íŠ¸ (ì„ íƒ)
    
    Returns:
        ìì—°ì–´ ì„¤ëª… ë¬¸ìì—´
    """
    if bedrock_client is None:
        bedrock_client = get_bedrock_client()
    
    if bedrock_client is None:
        # Fallback: ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ì„¤ëª…
        return _generate_fallback_explanation(prediction_result, movie_title)
    
    # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = _build_explanation_prompt(
        prediction_result,
        movie_title,
        user_liked_tags,
        user_disliked_tags
    )
    
    # Bedrock Claude í˜¸ì¶œ
    try:
        model_id = "anthropic.claude-3-haiku-20240307-v1:0"
        
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 300,  # ì„¤ëª…ì€ ì§§ê²Œ
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3  # ì¼ê´€ì„± ìˆëŠ” ì„¤ëª…
        }
        
        response = bedrock_client.invoke_model(
            modelId=model_id,
            body=json.dumps(request_body)
        )
        
        response_body = json.loads(response['body'].read())
        
        if 'content' in response_body and len(response_body['content']) > 0:
            explanation = response_body['content'][0]['text'].strip()
            return explanation
        else:
            return _generate_fallback_explanation(prediction_result, movie_title)
            
    except Exception as e:
        print(f"âš ï¸  LLM ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
        return _generate_fallback_explanation(prediction_result, movie_title)


def _build_explanation_prompt(
    prediction_result: Dict,
    movie_title: str,
    user_liked_tags: List[str],
    user_disliked_tags: List[str]
) -> str:
    """
    LLMìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    prob = prediction_result.get("probability", 0) * 100
    breakdown = prediction_result.get("breakdown", {})
    
    emotion_sim = breakdown.get("emotion_similarity", 0) * 100
    narrative_sim = breakdown.get("narrative_similarity", 0) * 100
    ending_sim = breakdown.get("ending_similarity", 0) * 100
    boost_score = breakdown.get("boost_score", 0)
    dislike_penalty = breakdown.get("dislike_penalty", 0)
    top_factors = breakdown.get("top_factors", [])
    
    # ì‚¬ìš©ì ì·¨í–¥ ì •ë³´
    liked_str = ""
    if user_liked_tags and len(user_liked_tags) > 0:
        liked_str = f"ì¢‹ì•„í•˜ëŠ” íƒœê·¸: {', '.join(user_liked_tags[:5])}"
    
    disliked_str = ""
    if user_disliked_tags and len(user_disliked_tags) > 0:
        disliked_str = f"ì‹«ì–´í•˜ëŠ” íƒœê·¸: {', '.join(user_disliked_tags[:5])}"
    
    # 30% ì´í•˜ì¼ ë•ŒëŠ” í¼ì„¼íŠ¸ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ
    if prob <= 30:
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™œ ì´ ì˜í™”ê°€ ì‚¬ìš©ìì˜ ì·¨í–¥ê³¼ ë§ì§€ ì•ŠëŠ”ì§€ 2-3ì¤„ë¡œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì˜í™”: "{movie_title}"

ì£¼ìš” ë¶ˆì¼ì¹˜ ìš”ì†Œ: {", ".join(top_factors)}
- ê°ì • ìœ ì‚¬ë„: {emotion_sim:.0f}%
- ì„œì‚¬ ìœ ì‚¬ë„: {narrative_sim:.0f}%
- ê²°ë§ ìœ ì‚¬ë„: {ending_sim:.0f}%

{liked_str}
{disliked_str}

ì¢‹ì•„í•˜ëŠ” ê²ƒ ë³´ë„ˆìŠ¤: {boost_score:.1f}
ì‹«ì–´í•˜ëŠ” ê²ƒ í˜ë„í‹°: {dislike_penalty:.1f}

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ì ì…ì¥ì—ì„œ "ë‹¹ì‹ "ìœ¼ë¡œ ì‹œì‘
2. êµ¬ì²´ì ì¸ í¼ì„¼íŠ¸(%)ë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
3. ì£¼ìš” ë¶ˆì¼ì¹˜ ì´ìœ ë¥¼ ì„¤ëª…
4. 2-3ì¤„ë¡œ ê°„ê²°í•˜ê²Œ

ì„¤ëª…ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
    else:
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™œ ì´ ì˜í™”ê°€ ì‚¬ìš©ìì—ê²Œ {prob:.0f}% ì í•©í•œì§€ 2-3ì¤„ë¡œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì˜í™”: "{movie_title}"
ë§Œì¡± í™•ë¥ : {prob:.0f}%

ì£¼ìš” ì¼ì¹˜ ìš”ì†Œ: {", ".join(top_factors)}
- ê°ì • ìœ ì‚¬ë„: {emotion_sim:.0f}%
- ì„œì‚¬ ìœ ì‚¬ë„: {narrative_sim:.0f}%
- ê²°ë§ ìœ ì‚¬ë„: {ending_sim:.0f}%

{liked_str}
{disliked_str}

ì¢‹ì•„í•˜ëŠ” ê²ƒ ë³´ë„ˆìŠ¤: {boost_score:.1f}
ì‹«ì–´í•˜ëŠ” ê²ƒ í˜ë„í‹°: {dislike_penalty:.1f}

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ì ì…ì¥ì—ì„œ "ë‹¹ì‹ "ìœ¼ë¡œ ì‹œì‘
2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜(%)ë¥¼ í¬í•¨
3. ì£¼ìš” ì¼ì¹˜ ìš”ì†Œë¥¼ ì–¸ê¸‰
4. 2-3ì¤„ë¡œ ê°„ê²°í•˜ê²Œ

ì„¤ëª…ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

    return prompt


def _generate_fallback_explanation(
    prediction_result: Dict,
    movie_title: str
) -> str:
    """
    LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ ì„¤ëª…
    """
    prob = prediction_result.get("probability", 0) * 100
    breakdown = prediction_result.get("breakdown", {})
    top_factors = breakdown.get("top_factors", ["ì·¨í–¥ ìš”ì†Œ"])
    
    explanation = f'"{movie_title}"ëŠ” ë‹¹ì‹ ì˜ ì·¨í–¥ê³¼ {prob:.0f}% ì¼ì¹˜í•©ë‹ˆë‹¤. '
    explanation += f'íŠ¹íˆ {", ".join(top_factors)}ê°€ ì˜ ë§ìŠµë‹ˆë‹¤. '
    explanation += 'ì´ ì˜ˆì¸¡ì€ í™•ë¥  ê¸°ë°˜ì´ë¯€ë¡œ ê°œì¸ì°¨ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
    
    return explanation


# CLI í…ŒìŠ¤íŠ¸
if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='A-5 ì„¤ëª… ìƒì„± í…ŒìŠ¤íŠ¸')
    parser.add_argument('--movie-title', default='ì‡¼ìƒí¬ íƒˆì¶œ')
    parser.add_argument('--prob', type=float, default=0.87)
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_result = {
        "probability": args.prob,
        "confidence": 0.92,
        "breakdown": {
            "emotion_similarity": 0.91,
            "narrative_similarity": 0.85,
            "ending_similarity": 0.78,
            "boost_score": 5.2,
            "dislike_penalty": 1.3,
            "top_factors": ["ì •ì„œ í†¤", "ì„œì‚¬ ì´ˆì "]
        }
    }
    
    bedrock_client = get_bedrock_client()
    
    explanation = generate_explanation(
        test_result,
        args.movie_title,
        user_liked_tags=["ë”°ëœ»í•´ìš”", "ì—¬ìš´ì´ ê¸¸ì–´ìš”", "ì”ì”í•´ìš”"],
        user_disliked_tags=["ë¬´ì„œì›Œìš”", "ê¸´ì¥ë¼ìš”"],
        bedrock_client=bedrock_client
    )
    
    print("\n" + "="*60)
    print(f"ì˜í™”: {args.movie_title}")
    print(f"ë§Œì¡± í™•ë¥ : {test_result['probability']:.1%}")
    print("="*60)
    print(f"\nğŸ“ ì„¤ëª…:\n{explanation}\n")
